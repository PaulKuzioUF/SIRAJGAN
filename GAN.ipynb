{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "filepath=\"c/users/pkuzi/documents\"\n",
        "a=pd.read_csv(filepath+'Dataset.csv')\n",
        "a.drop(columns = 'URL', axis = 1, inplace= True)\n",
        "a.drop(columns = 'Artmis', axis = 1, inplace= True)\n",
        "a.drop(columns = 'Google Safebrowsing', axis = 1, inplace= True)\n",
        "a.drop(columns = 'Fraudscore', axis = 1, inplace= True)\n",
        "a.drop(columns = 'CyberCrime', axis = 1, inplace= True)\n",
        "a.drop(columns = 'ESET', axis = 1, inplace= True)\n",
        "b=pd.read_csv(filepath+'Labels.csv')\n",
        "\n",
        "a=a.values.tolist()\n",
        "b=b['Labels'].tolist()\n",
        "\n"
      ],
      "metadata": {
        "id": "2mu56LqiDKBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import packages\n",
        "import os\n",
        "import torch \n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        " \n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "from typing import List\n",
        "\n",
        "class Generator(nn.Module):\n",
        "\n",
        "    def __init__(self, input_length: int):\n",
        "        super(Generator, self).__init__()\n",
        "        self.dense_layer = nn.Linear(int(input_length), int(input_length))\n",
        "        self.activation = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.activation(self.dense_layer(x))\n",
        "\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_length: int):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.dense = nn.Linear(int(input_length), 1);\n",
        "        self.activation = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.activation(self.dense(x))\n",
        "\n",
        "\n",
        "# Models\n",
        "generator = Generator(7)\n",
        "discriminator = Discriminator(7)\n",
        "\n",
        "def train(max_int: int = 128, batch_size: int = 10, training_steps: int = 25):\n",
        "    input_length = 7\n",
        "\n",
        "\n",
        "    # Optimizers\n",
        "    generator_optimizer = torch.optim.Adam(generator.parameters(), lr=0.001)\n",
        "    discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.001)\n",
        "\n",
        "    # loss\n",
        "    loss = nn.BCELoss()\n",
        "    for i in range(0,1000):\n",
        "      for i in range(training_steps):\n",
        "          # zero the gradients on each iteration\n",
        "          generator_optimizer.zero_grad()\n",
        "\n",
        "          # Create noisy input for generator\n",
        "          # Need float type instead of int\n",
        "          noise = torch.randint(0, 2, size=(batch_size, input_length)).float()\n",
        "          generated_data = generator(noise)\n",
        "\n",
        "          # Get next data\n",
        "          true_labels = b[i*10:10+i*10]\n",
        "          true_data = a[i*10:10+i*10]\n",
        "\n",
        "\n",
        "          true_labels = torch.tensor(true_labels).float()\n",
        "          true_data = torch.tensor(true_data).float()\n",
        "\n",
        "          # Train the generator\n",
        "          generator_discriminator_out = discriminator(generated_data)\n",
        "\n",
        "          generator_loss = loss(generator_discriminator_out, true_labels.unsqueeze(1))\n",
        "          generator_loss.backward()\n",
        "          generator_optimizer.step()\n",
        "\n",
        "          # Train the discriminator on the true/generated data\n",
        "          discriminator_optimizer.zero_grad()\n",
        "          true_discriminator_out = discriminator(true_data)\n",
        "          true_discriminator_loss = loss(true_discriminator_out, true_labels.unsqueeze(1))\n",
        "\n",
        "          generator_discriminator_out = discriminator(generated_data.detach())\n",
        "          generator_discriminator_loss = loss(generator_discriminator_out, torch.zeros(batch_size).unsqueeze(1))\n",
        "          discriminator_loss = (true_discriminator_loss + generator_discriminator_loss) / 2\n",
        "          discriminator_loss.backward()\n",
        "          discriminator_optimizer.step()\n",
        "\n",
        "train()"
      ],
      "metadata": {
        "id": "NUjABqjmEQEc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}